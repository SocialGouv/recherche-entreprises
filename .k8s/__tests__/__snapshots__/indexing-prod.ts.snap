// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`kosko generate --dev 1`] = `
"---
apiVersion: bitnami.com/v1alpha1
kind: SealedSecret
metadata:
  name: elastic-recherche-entreprises-write
  annotations:
    app.gitlab.com/app: socialgouv-recherche-entreprises
    app.gitlab.com/env: recherche-entreprises-209-gitlab3-dev2
    app.gitlab.com/env.name: gitlab3-dev2
  labels:
    application: v1-2-3-recherche-entreprises
    owner: recherche-entreprises
    team: recherche-entreprises
    cert: wildcard
  namespace: recherche-entreprises-209-gitlab3-dev2
spec:
  encryptedData:
    ELASTICSEARCH_URL: >-
      AgA0evdMnmx3uImqSzGIHorhP2zdv0hFREYZt0FLKi9Eg389OmU1f8CKgpOJp5LPedSAghc8HEd//YeqYRvhQZhfclkw15FZJX7xxz3H75wYJMuNxnLPz8cEyruuA2NrqVoCNuf8p06aI1hfhjNlIKnPjewR14hK5tdKVmsRc1bfPOygUhslbp+aDCbyCFAVFamhaHYHYKdBKZ4B3V+pgLfQvJl2Xfnm3ChXO9Y7ptnI7IJjyzpResdQwasAppc6onvOrGAdms4wW0TZQOsrRV/3JwFHwbqwiX8DzdwkvLlK37HwV7XddiHOQsa3Z+ONI5y9Uhbw2+3ynMi0h8dVOxHmjeq4iPVBqSTWgRfqomz7MR+MSQfNwaE/D20qlt1fzrFvNezc07XxwYxogUS9QFVe8vgXbeoOFmgUA25pKUsOVgjs+ulA5uH7fMv9JhF5H93250FE+/VcHS1wtUAZw67w9GndnpEgs/kmqR9juD4qVEslrEb36OmsZi4hkgNKh8kK2GybTTaTw4I5xSuWu0mpQqZR3i5M8biT/B0YStW1EkajX02obUyQKSJk8VjLwXIFQ726kse5sMh8Ste+z1lKEIfq6jOKZZ7sUiSTwuLuGTmEqy5mdcmkyeCgp4paYOyzKHhYDNXaoZkKguZP9DuOY+44g4uch9Uj3hGvZb+4dV41FGIJ3PB0YZbbxgHF3UA6iHGkZcITwxhn4lJADU7yJyQcrziDXccKa1yiGe9BOOjGn2+WOLF0lrLsA6Uxk70sEiwZygYJQCJGN6KsHPz7Resz6aF/YTY3K+m65VeI4g==
    ELASTICSEARCH_API_KEY: >-
      AgAw0rLyRSJJHgwBKDwtTfrBJtMTZ2jaQ07AZArXOsCazbaGOCfLtdtoB3tmlZw+fPYkLpCcWEDypjjt2qvoaMTQJp/LZcyXG69ccPLTj5wDzTSiYsIIewBNN6d0A71lUdbtAFgdyFPrxjYIDuj9SVtQqRjv6Fd/gmEnAsGh2szYRfeRIse8zqI/ICWuBpfidZ7lLDzJbTnCK4AYkan2zWqk4Xp5X8owyAaKc3gkG3CKDiR0Re+cAdfpQ2VJ7KX22vnn8jtu98i98vwGtG2iJngX7oLWXgYxR+ptkKdSt54lwzRCCfRgEI32Rl0JNHcY8QpYq+SVlxpMpNNLk5rp7NscR6AeU+YVQH0R+ZidEPC3Ys/ELIZ2wLd/++DKVRFQfgSoC1c0DkBy+u49Ye/5eV0m8p0FW+ch12ylVynnWvbIfhYsRQx2c9xsI7KN3ysUcktWjDech2qI4zpkTUyV+KhWqVpO2LjbJoD6TFOVgd/CoFGeNB7Yjds0ccerXk1z8lirdm2irSJ+B1szZBzGCVXGwqnPu/KNebaPdwk+Dy4MH3fFe9ktwHcSJuiwBsnx38FuFHI0qWDTk/StOzprYD16WoAihB+LCVrOvJEJTnAWf5lCs2QStRiD5gFAHMtdW/Z8Q29QgXI8s+19YZ3Wz6JmJYgUKayYR/7qZqV5eD5aVQR/BphmZiH2SJh4zJ5lFk3r6a02/OwlwqIVfCYFmm9thFHsbJr5A3698128+KRrB/WLTKV1AvmPWWcDoj7HbFi+tYobtwNQpCQWw28=
  template:
    metadata:
      annotations:
        app.gitlab.com/app: socialgouv-recherche-entreprises
        app.gitlab.com/env: recherche-entreprises-209-gitlab3-dev2
        app.gitlab.com/env.name: gitlab3-dev2
      name: elastic-recherche-entreprises-write
      labels:
        application: v1-2-3-recherche-entreprises
        owner: recherche-entreprises
        team: recherche-entreprises
        cert: wildcard
    type: Opaque
---
apiVersion: v1
kind: ConfigMap
data:
  get-data.sh: >-
    #!/bin/bash


    # borrowed from annuaire entreprise  :

    # https://github.com/etalab/api-annuaire-entreprises/tree/master/db/init


    geodir=\${DATA_DIR}/geo


    mkdir -p $geodir


    echo \\"-- Download datasets\\"


    for d in \`seq -w 1 19\` 2A 2B \`seq 21 74\` \`seq 76 95\` 98 \\"\\"; do
      wget --progress=bar:force:noscroll -q --show-progress https://files.data.gouv.fr/geo-sirene/last/dep/geo_siret_$d.csv.gz --directory-prefix=$geodir
      gunzip \${geodir}/geo_siret_$d.csv.gz
    done


    #Cas particulier Paris

    for d in \`seq -w 1 20\`; do
      wget --progress=bar:force:noscroll -q --show-progress https://files.data.gouv.fr/geo-sirene/last/dep/geo_siret_751$d.csv.gz --directory-prefix=$geodir
      gunzip \${geodir}/geo_siret_751$d.csv.gz
    done


    #Cas particulier DOM

    for d in \`seq -w 1 8\`; do
      wget --progress=bar:force:noscroll -q --show-progress https://files.data.gouv.fr/geo-sirene/last/dep/geo_siret_97$d.csv.gz --directory-prefix=$geodir
      gunzip \${geodir}/geo_siret_97$d.csv.gz
    done


    # SIRET data

    wget --progress=bar:force:noscroll -q --show-progress
    https://files.data.gouv.fr/insee-sirene/StockUniteLegale_utf8.zip
    --directory-prefix=$DATA_DIR


    # WEEZ data

    wget --progress=bar:force:noscroll -q --show-progress
    https://github.com/SocialGouv/siret2idcc/blob/master/data/WEEZ.csv?raw=true
    -O \${DATA_DIR}/WEEZ.csv
  assemble_data.py: |
    \\"\\"\\"CDTN Entreprises data assembler

    This script assembles data from different places and creates a new file that
    will be used as source for our search index.

    \\"\\"\\"
    import argparse
    import pandas as pd
    import numpy as np
    from os import listdir
    from os.path import isfile, join


    def read_siren(stock_unite_legale_file):
        \\"\\"\\" Read SIREN Stock Unite Legale

        Parameters
        ----------
        stock_unite_legale_file: str
            The location of the CSV or ZIP file

        Returns
        -------
        employeurs
            a Pandas dataframe containing the list of all companies that are still open
            and employ people
        \\"\\"\\"
        trancheEffectifsUniteLegale = \\"trancheEffectifsUniteLegale\\"
        categorieJuridiqueUniteLegale = \\"categorieJuridiqueUniteLegale\\"
        nomenclatureActivitePrincipaleUniteLegale = \\"nomenclatureActivitePrincipaleUniteLegale\\"
        categorieEntreprise = \\"categorieEntreprise\\"
        activitePrincipaleUniteLegale = \\"activitePrincipaleUniteLegale\\"

        selection = [\\"siren\\", \\"sigleUniteLegale\\", \\"nomUniteLegale\\", \\"nomUsageUniteLegale\\",
                     'denominationUniteLegale', \\"denominationUsuelle1UniteLegale\\", \\"denominationUsuelle2UniteLegale\\",
                     \\"denominationUsuelle3UniteLegale\\", activitePrincipaleUniteLegale,
                     trancheEffectifsUniteLegale, categorieJuridiqueUniteLegale,
                     nomenclatureActivitePrincipaleUniteLegale, categorieEntreprise]

        etatAdmin = \\"etatAdministratifUniteLegale\\"
        caractereEmployeur = \\"caractereEmployeurUniteLegale\\"

        # we only select columns in use and convert to categorical dtype
        # in order to decrease the dataframe memory footprint
        cols = selection + [etatAdmin, caractereEmployeur]
        raw = pd.read_csv(stock_unite_legale_file, usecols=cols,
                          dtype={etatAdmin: \\"category\\", caractereEmployeur: \\"category\\",
                                 trancheEffectifsUniteLegale: \\"category\\",
                                 categorieJuridiqueUniteLegale: \\"category\\",
                                 nomenclatureActivitePrincipaleUniteLegale: \\"category\\",
                                 activitePrincipaleUniteLegale: \\"category\\",
                                 categorieEntreprise: \\"category\\"}, )

        is_ouvert = raw[etatAdmin] == \\"A\\"
        is_employeur = raw[caractereEmployeur] == \\"O\\"
        is_admin = raw[etatAdmin] == \\"A\\"

        employeurs = raw[is_ouvert & is_employeur & is_admin]

        return employeurs[selection]


    def read_geo(geo_directory):
        \\"\\"\\" Read GEO data

        Parameters
        ----------
        geo_directory: str
            The directory containing geo data for all regions

        Returns
        -------
        all_geo
            a Pandas dataframe containing geo information for all open companies
        \\"\\"\\"
        geo_files = [f for f in listdir(
            geo_directory) if isfile(join(geo_directory, f))]
        geo_selection = [\\"enseigne1Etablissement\\", \\"enseigne2Etablissement\\", \\"enseigne3Etablissement\\", \\"denominationUsuelleEtablissement\\", \\"activitePrincipaleEtablissement\\",
                         'siren', 'siret', 'codePostalEtablissement', 'libelleCommuneEtablissement', \\"etatAdministratifEtablissement\\", \\"geo_adresse\\"]
        geo = {}
        for file in geo_files:
            geo[file] = pd.read_csv(
                geo_directory + file, dtype={\\"codePostalEtablissement\\": np.dtype(str),
                                             \\"etatAdministratifEtablissement\\": \\"category\\",
                                             \\"activitePrincipaleEtablissement\\": \\"category\\"
                                             }, usecols=geo_selection
            )

        all_geo = pd.concat(geo.values(), ignore_index=True).dropna(
            subset=['siret'])

        all_geo = all_geo.astype(dtype={\\"codePostalEtablissement\\": np.dtype(str),
                                        \\"etatAdministratifEtablissement\\": \\"category\\",
                                        \\"activitePrincipaleEtablissement\\": \\"category\\",
                                        })

        all_geo = all_geo[all_geo[\\"etatAdministratifEtablissement\\"] == \\"A\\"]

        return all_geo


    def read_idcc(idcc_file):
        \\"\\"\\" Read IDCC data

        Parameters
        ----------
        idcc_file: str
            The location of the CSV file containing associations between companies and their \\"convention collectives\\", (aka WEEZ)

        Returns
        -------
        idccs
            a Pandas dataframe containing siret / idcc associations
        \\"\\"\\"
        idccs = pd.read_csv(idcc_file, usecols=[\\"SIRET\\", \\"IDCC\\"]).rename(
            columns={\\"SIRET\\": \\"siret\\", \\"IDCC\\": \\"idcc\\"})
        # drop unknown
        unknown = idccs[\\"idcc\\"] == 9999
        idccs = idccs.drop(idccs[unknown].index)
        return idccs


    def assemble(siren, geo, idcc, output):
        sirenGeo = pd.merge(siren, geo, on='siren')
        merged = pd.merge(sirenGeo, idcc, how='left', on='siret')

        # add etablissement counts
        etsCounts = merged.siren.value_counts().rename_axis(
            'siren').reset_index(name='etablissements')
        withEts = pd.merge(merged, etsCounts, on='siren')

        # persits as CSV file
        withEts.astype({'idcc': 'Int64'}).to_csv(output)


    def main():
        parser = argparse.ArgumentParser(description=__doc__)
        parser.add_argument(
            'siren_file',
            type=str,
            help=\\"Location of the StockUniteLegale CSV or ZIP file\\"
        )
        parser.add_argument(
            'geo_directory',
            type=str,
            help=\\"Location of the directory containing all the Geo CSV files\\"
        )
        parser.add_argument(
            'idcc_file',
            type=str,
            help=\\"Location of the siret/idcc CSV file (aka WEEZ)\\"
        )
        parser.add_argument(
            'output_file',
            type=str,
            help=\\"Location of the output file\\"
        )

        args = parser.parse_args()

        print(\\"Read SIREN data\\")
        siren = read_siren(args.siren_file)

        print(\\"Read GEO data\\")
        geo = read_geo(args.geo_directory)

        print(\\"Read IDCC data\\")
        idcc = read_idcc(args.idcc_file)

        print(\\"Assemble datasets\\")
        assemble(siren, geo, idcc, args.output_file)


    if __name__ == \\"__main__\\":
        main()
  requirements.txt: |
    numpy
    pandas
metadata:
  name: config-map-files-ccff889
  annotations:
    app.gitlab.com/app: socialgouv-recherche-entreprises
    app.gitlab.com/env: recherche-entreprises-209-gitlab3-dev2
    app.gitlab.com/env.name: gitlab3-dev2
  labels:
    application: v1-2-3-recherche-entreprises
    owner: recherche-entreprises
    team: recherche-entreprises
    cert: wildcard
  namespace: recherche-entreprises-209-gitlab3-dev2
---
apiVersion: batch/v1
kind: Job
metadata:
  name: update-index-ccff889
  annotations:
    app.gitlab.com/app: socialgouv-recherche-entreprises
    app.gitlab.com/env: recherche-entreprises-209-gitlab3-dev2
    app.gitlab.com/env.name: gitlab3-dev2
  labels:
    application: v1-2-3-recherche-entreprises
    owner: recherche-entreprises
    team: recherche-entreprises
    cert: wildcard
  namespace: recherche-entreprises-209-gitlab3-dev2
spec:
  backoffLimit: 3
  template:
    spec:
      containers:
        - name: update-index
          image: >-
            harbor.fabrique.social.gouv.fr/cdtn/recherche-entreprises-index:1.2.3
          volumeMounts:
            - name: data
              mountPath: /data
          env:
            - name: ASSEMBLY_FILE
              value: /data/assembly.csv
          envFrom:
            - secretRef:
                name: elastic-recherche-entreprises-write
      restartPolicy: Never
      volumes:
        - name: data
          emptyDir: {}
        - configMap:
            name: config-map-files-ccff889
            defaultMode: 511
          name: local-files
      nodeSelector:
        kubernetes.io/hostname: aks-system0-38313369-vmss000001
      initContainers:
        - args:
            - '-c'
            - >

              apt-get update -y && apt-get install -y wget 


              export DATA_DIR=\\"/data\\"


              cd /data


              echo \\"running get-data.sh...\\"


              /mnt/scripts/get-data.sh


              pip3 install -r /mnt/scripts/requirements.txt


              echo \\"running assemble_data.py...\\"


              python3 /mnt/scripts/assemble_data.py
              $DATA_DIR/StockUniteLegale_utf8.zip  $DATA_DIR/geo/
              $DATA_DIR/WEEZ.csv $DATA_DIR/assembly.csv
          command:
            - sh
          image: python:3.9.4
          imagePullPolicy: Always
          name: download-data
          volumeMounts:
            - name: data
              mountPath: /data
            - mountPath: /mnt/scripts
              name: local-files
    metadata:
      annotations:
        app.gitlab.com/app: socialgouv-recherche-entreprises
        app.gitlab.com/env: recherche-entreprises-209-gitlab3-dev2
        app.gitlab.com/env.name: gitlab3-dev2
      labels:
        application: v1-2-3-recherche-entreprises
        owner: recherche-entreprises
        team: recherche-entreprises
        cert: wildcard
"
`;
